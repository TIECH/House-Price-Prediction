{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.linear_model import Ridge, LassoCV,LassoLarsCV, ElasticNet\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(prediction,score):\n",
    "    now = datetime.datetime.now()\n",
    "    sub_file = 'submission_'+str(score)+'_'+str(now.strftime(\"%Y-%m-%d-%H-%M\"))+'.csv'\n",
    "    #sub_file = 'prediction_training.csv'\n",
    "    print ('Creating submission: ', sub_file)\n",
    "    pd.DataFrame({'Id': test['Id'].values, 'SalePrice': prediction}).to_csv(sub_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train need to be test when do test prediction\n",
    "def data_preprocess(train,test):\n",
    "    outlier_idx = [4,11,13,20,46,66,70,167,178,185,199, 224,261, 309,313,318, 349,412,423,440,454,477,478, 523,540, 581,588,595,654,688, 691, 774, 798, 875, 898,926,970,987,1027,1109, 1169,1182,1239, 1256,1298,1324,1353,1359,1405,1442,1447]\n",
    "    train.drop(train.index[outlier_idx],inplace=True)\n",
    "    all_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\n",
    "                          test.loc[:,'MSSubClass':'SaleCondition']))\n",
    "    \n",
    "    to_delete = ['Alley','FireplaceQu','PoolQC','Fence','MiscFeature']\n",
    "    all_data = all_data.drop(to_delete,axis=1)\n",
    "\n",
    "    train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "    #log transform skewed numeric features\n",
    "    numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "    skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "    skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "    skewed_feats = skewed_feats.index\n",
    "    all_data[skewed_feats] = np.log1p(all_data[skewed_feats])\n",
    "    all_data = pd.get_dummies(all_data)\n",
    "    all_data = all_data.fillna(all_data.mean())\n",
    "    X_train = all_data[:train.shape[0]]\n",
    "    X_test = all_data[train.shape[0]:]\n",
    "    y = train.SalePrice\n",
    "\n",
    "    return X_train,X_test,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\") # read train data\n",
    "test = pd.read_csv(\"test.csv\") # read test data\n",
    "\n",
    "X_train,X_test,y_train = data_preprocess(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error_(ground_truth, predictions):\n",
    "    return mean_squared_error(ground_truth, predictions) ** 0.5\n",
    "RMSE = make_scorer(mean_squared_error_, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ensemble(object):\n",
    "    def __init__(self, n_folds, stacker, base_models):\n",
    "        self.n_folds = n_folds\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "    def fit_predict(self, train, test, ytr):\n",
    "        X = train.values\n",
    "        y = ytr.values\n",
    "        T = test.values\n",
    "        folds = list(KFold(len(y), n_folds=self.n_folds, shuffle=True, random_state=0)) \n",
    "        S_train = np.zeros((X.shape[0],len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0],len(self.base_models)))\n",
    "        for i,reg in enumerate(base_models):\n",
    "            print(\"Fitting the base model...\")\n",
    "            S_test_i = np.zeros((T.shape[0],len(folds)))\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "                reg.fit(X_train,y_train)\n",
    "                y_pred = reg.predict(X_holdout)[:]\n",
    "                S_train[test_idx,i] = y_pred\n",
    "                S_test_i[:,j] = reg.predict(T)[:]\n",
    "            S_test[:,i] = S_test_i.mean(1)\n",
    "        print(\"Stacking base models...\")\n",
    "        \n",
    "        # tuning the stacker\n",
    "        param_grid = {'alpha': [1e-3,5e-3,1e-2,5e-2,1e-1,0.2,0.3,0.4,0.5,0.8,1e0,3,5,7,1e1],}\n",
    "        grid = GridSearchCV(estimator=self.stacker, \n",
    "                            param_grid=param_grid,\n",
    "                            n_jobs=1,\n",
    "                            cv=5,\n",
    "                            scoring=RMSE\n",
    "                           )\n",
    "        grid.fit(S_train,y)\n",
    "        try:\n",
    "            print('Param grid:')\n",
    "            print(param_grid)\n",
    "            print('Best Params:')\n",
    "            print(grid.best_params_)\n",
    "            print('Best CV Score:')\n",
    "            print(-grid.best_score_)\n",
    "            print('Best estimator:')\n",
    "            print(grid.best_estimator_)\n",
    "            print(message)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        y_pred = grid.predict(S_test)[:]\n",
    "        return y_pred, -grid.best_score_\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model library \n",
    "\n",
    "base_models = [\n",
    "        RandomForestRegressor(\n",
    "            n_jobs=1, random_state=0,\n",
    "            n_estimators=500, max_features=25, max_depth=11\n",
    "        ),\n",
    "        ExtraTreesRegressor(\n",
    "            n_jobs=1, random_state=0, \n",
    "            n_estimators=500, max_features=20\n",
    "        ),\n",
    "        GradientBoostingRegressor(\n",
    "            random_state=0, \n",
    "            n_estimators=500, max_features=10, max_depth=6,\n",
    "            learning_rate=0.05, subsample=0.8\n",
    "        ),\n",
    "        XGBRegressor(\n",
    "            seed=0,\n",
    "            n_estimators=500, max_depth=7,\n",
    "            learning_rate=0.05, subsample=0.8, colsample_bytree=0.85\n",
    "        ),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensem = ensemble(\n",
    "    n_folds=5,\n",
    "    stacker=Ridge(),\n",
    "    base_models=base_models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the base model...\n",
      "Fitting the base model...\n",
      "Fitting the base model...\n",
      "Fitting the base model...\n",
      "Stacking base models...\n",
      "Param grid:\n",
      "{'alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.8, 1.0, 3, 5, 7, 10.0]}\n",
      "Best Params:\n",
      "{'alpha': 0.1}\n",
      "Best CV Score:\n",
      "0.106471240582\n",
      "Best estimator:\n",
      "Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n"
     ]
    }
   ],
   "source": [
    "y_pred, score = ensem.fit_predict(X_train,X_test,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
